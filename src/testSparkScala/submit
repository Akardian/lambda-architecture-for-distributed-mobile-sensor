HDFS_CONTAINER=lambda_hadoop-datanode.p9ui3d0x46fhizffwucvrs73y.nl3zor25hsmv80vcuqa25plbb
SPARK_CONTAINER=lambda_spark-master.1.nwjv3r7aikc5e06b7d85dafqh

#Save jars to HDFS
#Local   container only
docker cp build/libs/Spark-Test-v01-all.jar $HDFS_CONTAINER:tmp/

docker exec $HDFS_CONTAINER hdfs dfs -mkdir /spark-jars
docker exec $HDFS_CONTAINER hdfs dfs -put -f tmp/Spark-Test-v01-all.jar /spark-jars

# Run on a Spark standalone cluster in cluster deploy mode
docker exec $SPARK_CONTAINER /opt/bitnami/spark/bin/spark-submit \
  --class scala.Test \
  --master spark://spark-master:7077 \
  --deploy-mode cluster \
  --executor-memory 2G \
  --total-executor-cores 2 \
  hdfs://hadoop-namenode:50070/spark-jars/Spark-Test-v01-all.jar