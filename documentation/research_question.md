# Research Question

Scalability of Spark Streaming

## Introduction

The lambda architecture is using two different data processing layer. The "batch" layer is for processing older data and the "streaming" layer for the new data. This splitting of responsibility reduces the amount of data the "streaming" layer needs to process. This leads to faster processing times and the need to optimise the program.
But in return it increases the architecture complexity. To find out at which point it makes sense to use a "batch" layer to support the "streaming" we will measure the processing time of different "streaming" applications.

The data we are using for the experiment are ROS Odometry coordinates and Find3 WiFi strength data. Both are going to be artificially generated by a java program. The analytic software "Apache Spark Streaming" is going to be responsible for processing and transforming the data and will provide us with the processing time. The java program is connected to "Apache Spark" through the streaming platform "Apache Kafka".

###  Experiments

The experiment is going to include 4 different data transformation.

#### Normalisation

This transformation includes the ingestion, hierarchy flattening, normalisation and average calculation in a single line. All of these transformation are having a constant complexity and are not affected by other lines. In production environments the average calculation is not a constant complexity but for this experiment the number of list entry's is always so same and can be seen as such.
Since this transformation is always necessary it will be included in all other transformations.

##### Expectations

As all the calculation are of constant complexity the expectation is that the calculation time will not increase with so number of messages send. Adding more executor for parallel calculations will only increase the calculation speed if more than one message is present at a time. If this is the case the the calculation speed should scale linear.

#### Spark aggregation

This transformation is using the aggregation min, max, average and count of spark. All those function come with the spark suck framework. Those task need data of other table lines but spark is using intermediate result to reduce calculation time.

##### Expectations

The calculation should not increase over time since spark is using intermediate results and it is not necessary to iterate of all entry's. Adding more executor should decrease the calculation time if multiple messages are present at a time.

#### Custom aggregation inaccurate 

This aggregation is calculating the total distance travelled. This is done by calculating the distance between 2 odometry points, but it is using only the most recent point as an intermediate value the executor has access to. This results in an inaccurate result since the correct point sequence is not granted.

##### Expectations

The calculation should not increase over time since only the most recent entry is saved. Adding more executor should decrease the calculation time if multiple messages are present at a time.

The more executor are added to the calculation the bigger error is going to be.

#### Custom aggregation exact

This aggregation is calculating the total distance travelled. This is done by calculating the distance between 2 odometry points. This aggregation compared to the inaccurate is saving all intermediate values. This allow for an accurate result, but the calculation time increases over time. 

##### Expectations

For this aggregation to work it is necessary to sort(quadratic time) the entire table. This leads to bigger calculation time the bigger the table gets. Furthermore most of the calculation need to be done on the last node and more executor are not going to reduce the calculation time by much or even increase the time because the large data set needs to be send to the last executor.

#### Tests

To test the scalability we are going to scale 2 parameter. The first one is the number of executor running which allows for parallel calculations. The second parameter is the amount of messages which are send per second. The higher the amount of messages are send the higher the stress and the need to scale the system.

The output is going to be the processing time of the spark process. Combined with the number of send messages we can observe the processing time change over time.

| Messages send every X seconds | Number of executor |
|-------------------------------|--------------------|
| 30                            | 1                  |
| 30                            | 2                  |
| 30                            | 4                  |
|                               |                    |
| 10                            | 1                  |
| 10                            | 2                  |
| 10                            | 4                  |
|                               |                    |
| 1                             | 1                  |
| 1                             | 2                  |
| 1                             | 4                  |

#### Test Hardware

- todo:

### Real World Sample Data

```json
{
    {
        "senderName": "maxpixel",
        "location": "r287",
        "findTimestamp": "1610636575427",
        "gpsCoordinate": {
        "lat": "53.557857990317935",
        "lon": "10.023013328928275",
        "alt": "62.60000228881836"
    },
    "wifiData": {
        "wifiData": {
            "bc:26:c7:40:90:ee": -87,
            "bc:26:c7:40:90:ec": -88,
            "bc:26:c7:7c:cd:23": -76,
            "bc:26:c7:40:90:ed": -88,
            "bc:26:c7:7c:cd:22": -76,
            "bc:26:c7:7c:cd:21": -76,
            "14:59:c0:20:39:80": -91,
            "bc:26:c7:7c:cd:2e": -76,
            "bc:26:c7:7c:cd:2d": -77,
            "bc:26:c7:40:90:e3": -83,
            "bc:26:c7:7c:cd:2c": -77,
            "bc:26:c7:7c:cd:4e": -89,
            "bc:26:c7:7c:cd:4d": -89,
            "bc:26:c7:40:90:e1": -83,
            "bc:26:c7:40:90:e2": -83,
            "cc:ce:1e:ae:39:be": -39,
            "cc:ce:1e:ae:39:bf": -47,
            "a0:cf:5b:69:6b:f0": -90
        }
    }
}
```